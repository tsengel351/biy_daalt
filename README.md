# BERT Embedding + Classification Model –•–∞—Ä—å—Ü—É—É–ª–∞–ª—Ç

## üéØ –ó–æ—Ä–∏–ª–≥–æ
BERT-–∏–π–Ω —Ö—É–≤–∏–ª–±–∞—Ä—É—É–¥–∞–∞—Ä (BERT-base, BERT-large, DistilBERT, RoBERTa, ALBERT) —Ç–µ–∫—Å—Ç–∏–π–≥ –≤–µ–∫—Ç–æ—Ä –±–æ–ª–≥–æ–∂, –∞–Ω–≥–∏–ª–∞—Ö –∑–∞–≥–≤–∞—Ä—É—É–¥—Ç–∞–π (Logistic Regression, AdaBoost, Random Forest, LSTM) —Ö–æ—Å–ª—É—É–ª–∞–Ω IMDB –º—ç–¥—Ä—ç–º–∂–∏–π–Ω –∞–Ω–≥–∏–ª–ª—ã–Ω “Ø—Ä –¥“Ø–Ω–≥ —Ö–∞—Ä—å—Ü—É—É–ª–∞—Ö.

## üìä –î–∞—Ç–∞—Å–µ—Ç
- IMDB 50K (Train 40k / Test 10k)  
- –≠–µ—Ä—ç–≥ / –°”©—Ä”©–≥ –∫–∏–Ω–æ —à“Ø“Ø–º–∂

## üîß –¢–µ—Ö–Ω–æ–ª–æ–≥–∏
- Embedding: HuggingFace Transformers (fine-tune —Ö–∏–π—Ö–≥“Ø–π)
- ML: scikit-learn (LR, AdaBoost, RF)
- DL: TensorFlow/Keras (LSTM)
- Evaluation: RepeatedStratifiedKFold (5 folds √ó 4 repeats = 20 runs)
- Metrics: Accuracy, Precision, Recall, F1, ROC-AUC

## üöÄ –ê—à–∏–≥–ª–∞—Ö –∑–∞–∞–≤–∞—Ä
```bash
pip install -r requirements.txt
# Embedding —Ñ–∞–π–ª—É—É–¥—ã–≥ embeddings/ –¥–æ—Ç–æ—Ä –±–∞–π—Ä–ª—É—É–ª–Ω–∞
# –Ω—ç—Ä—à–∏–ª: {model_name}_train_embeddings.npy, {model_name}_train_labels.npy, {model_name}_test_embeddings.npy, {model_name}_test_labels.npy
python main.py# biy_daalt
